{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from models import CnnModel, CrnnLongModel, CrnnModel, RnnModel, MambaVisionModel\n",
    "from train import main_train, validate_test, record_matrix\n",
    "from Paras import Para\n",
    "from data_loader import torch_dataset_loader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MambaVision model\n",
    "## Define Paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Para.learning_rate = 1e-5\n",
    "Para.batch_size = 20\n",
    "Para.epoch_num = 50\n",
    "\n",
    "train_loader = torch_dataset_loader(Para.TRAIN_DATA_PATH, Para.batch_size, True, Para.kwargs)\n",
    "validation_loader = torch_dataset_loader(Para.VAL_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "test_loader = torch_dataset_loader(Para.TEST_DATA_PATH, Para.batch_size, False, Para.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MambaVision = MambaVisionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp out: torch.Size([20, 1, 448, 128])\n",
      "chunk out: torch.Size([20, 1, 90, 128])\n",
      "fetures out: torch.Size([20, 640, 3, 4])\n",
      "mamba in: torch.Size([20, 6, 7680])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmain_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMambaVision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMambaVisionModel.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMambaVisionModel.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPara\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPara\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/docker/WhatIsThisMusic/scripts/train.py:129\u001b[0m, in \u001b[0;36mmain_train\u001b[0;34m(model, train_loader, valid_loader, log_name, save_name, lr, epoch_num)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Para\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m    128\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 129\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m validation_loss, validation_accuracy \u001b[38;5;241m=\u001b[39m validate_test(model, epoch, use_loader\u001b[38;5;241m=\u001b[39mvalid_loader)\n\u001b[1;32m    132\u001b[0m t_loss\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/docker/WhatIsThisMusic/scripts/train.py:27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epoch, train_loader, optimizer, versatile)\u001b[0m\n\u001b[1;32m     24\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m bce_loss(predicted, target)\n\u001b[1;32m     30\u001b[0m accuracy_value \u001b[38;5;241m=\u001b[39m accuracy_function(predicted, target)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/docker/WhatIsThisMusic/scripts/models.py:80\u001b[0m, in \u001b[0;36mMambaVisionModel.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmamba in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconcat\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#concat = concat.permute(0,2,1)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m outMamba \u001b[38;5;241m=\u001b[39m \u001b[43mMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmamba out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutMamba\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#out3 = self.fcBlock1(fetures_flat3)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#out = torch.cat((out2,out3),dim=1)        \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:57\u001b[0m, in \u001b[0;36mMamba.__init__\u001b[0;34m(self, d_model, d_state, d_conv, expand, dt_rank, dt_min, dt_max, dt_init, dt_scale, dt_init_floor, conv_bias, bias, use_fast_path, layer_idx, device, dtype)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_conv \u001b[38;5;241m=\u001b[39m d_conv\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand \u001b[38;5;241m=\u001b[39m expand\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_rank \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m16\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m dt_rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dt_rank\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fast_path \u001b[38;5;241m=\u001b[39m use_fast_path\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "res = main_train(model=MambaVision, \n",
    "                 train_loader=train_loader,\n",
    "                 valid_loader=validation_loader,\n",
    "                 log_name='MambaVisionModel.json',\n",
    "                 save_name='MambaVisionModel.pt',\n",
    "                 lr=Para.learning_rate,\n",
    "                 epoch_num=Para.epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(res['train_accu'], c='b', label='Training set accuracy')\n",
    "plt.plot(res['valid_accu'], c='r', label='Validation set accuracy')\n",
    "plt.title('Accuracy vs Epochs / MambaVision Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para.MODEL_SAVE_FOlD = './'\n",
    "MambaVision.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'modelsMambaVisionModel.pt'))\n",
    "validate_test(model=MambaVision, epoch=0, use_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MambaVision.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'modelsMambaVisionModel.pt'))\n",
    "record_matrix(model=MambaVision, use_loader=test_loader, log_name='MambaVisionMatrix.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "## Define Paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para.learning_rate = 1e-5\n",
    "Para.batch_size = 20\n",
    "Para.epoch_num = 50\n",
    "\n",
    "train_loader = torch_dataset_loader(Para.TRAIN_DATA_PATH, Para.batch_size, True, Para.kwargs)\n",
    "validation_loader = torch_dataset_loader(Para.VAL_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "test_loader = torch_dataset_loader(Para.TEST_DATA_PATH, Para.batch_size, False, Para.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = CnnModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = main_train(model=CNN, \n",
    "                 train_loader=train_loader,\n",
    "                 valid_loader=validation_loader,\n",
    "                 log_name='CnnModel.json',\n",
    "                 save_name='CnnModel.pt',\n",
    "                 lr=Para.learning_rate,\n",
    "                 epoch_num=Para.epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(res['train_accu'], c='b', label='Training set accuracy')\n",
    "plt.plot(res['valid_accu'], c='r', label='Validation set accuracy')\n",
    "plt.title('Accuracy vs Epochs / CNN Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CnnModel.pt'))\n",
    "validate_test(model=CNN, epoch=0, use_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CnnModel.pt'))\n",
    "record_matrix(model=CNN, use_loader=test_loader, log_name='CnnMatrix.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRNN Model\n",
    "## Paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para.learning_rate = 1e-5\n",
    "Para.batch_size = 20\n",
    "Para.epoch_num = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNN = CrnnModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = main_train(model=CRNN, \n",
    "                 train_loader=train_loader,\n",
    "                 valid_loader=validation_loader,\n",
    "                 log_name='CrnnModel.json',\n",
    "                 save_name='CrnnModel.pt',\n",
    "                 lr=Para.learning_rate,\n",
    "                 epoch_num=Para.epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(res['train_accu'], c='b', label='Training set accuracy')\n",
    "plt.plot(res['valid_accu'], c='r', label='Validation set accuracy')\n",
    "plt.title('Accuracy vs Epochs / CRNN Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CrnnModel.pt'))\n",
    "validate_test(model=CRNN, epoch=0, use_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CrnnModel.pt'))\n",
    "record_matrix(model=CRNN, use_loader=test_loader, log_name='CrnnMatrix.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCRNN Model\n",
    "## Paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para.learning_rate = 1e-5\n",
    "Para.batch_size = 20\n",
    "Para.epoch_num = 60\n",
    "\n",
    "train_loader = torch_dataset_loader(Para.LA_TRAIN_DATA_PATH, Para.batch_size, True, Para.kwargs)\n",
    "validation_loader = torch_dataset_loader(Para.LA_VAL_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "test_loader = torch_dataset_loader(Para.LA_TEST_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "\n",
    "LCRNN = CrnnLongModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = main_train(model=LCRNN, \n",
    "                 train_loader=train_loader,\n",
    "                 valid_loader=validation_loader,\n",
    "                 log_name='CrnnLongModel.json',\n",
    "                 save_name='CrnnLongModel.pt',\n",
    "                 lr=Para.learning_rate,\n",
    "                 epoch_num=Para.epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(res['train_accu'], c='b', label='Training set accuracy')\n",
    "plt.plot(res['valid_accu'], c='r', label='Validation set accuracy')\n",
    "plt.title('Accuracy vs Epochs / CRNN Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCRNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CrnnLongModel.pt'))\n",
    "validate_test(model=LCRNN, epoch=0, use_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCRNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'CrnnLongModel.pt'))\n",
    "record_matrix(model=LCRNN, use_loader=test_loader, log_name='CrnnLongMatrix.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para.learning_rate = 1e-5\n",
    "Para.batch_size = 32\n",
    "Para.epoch_num = 40\n",
    "\n",
    "train_loader = torch_dataset_loader(Para.LA_TRAIN_DATA_PATH, Para.batch_size, True, Para.kwargs)\n",
    "validation_loader = torch_dataset_loader(Para.LA_VAL_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "test_loader = torch_dataset_loader(Para.LA_TEST_DATA_PATH, Para.batch_size, False, Para.kwargs)\n",
    "\n",
    "RNN = RnnModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = main_train(model=RNN, \n",
    "                 train_loader=train_loader,\n",
    "                 valid_loader=validation_loader,\n",
    "                 log_name='RnnModel.json',\n",
    "                 save_name='RnnModel.pt',\n",
    "                 lr=Para.learning_rate,\n",
    "                 epoch_num=Para.epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(res['train_accu'], c='b', label='Training set accuracy')\n",
    "plt.plot(res['valid_accu'], c='r', label='Validation set accuracy')\n",
    "plt.title('Accuracy vs Epochs / RCNN Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.cuda().load_state_dict(torch.load(Para.MODEL_SAVE_FOlD + 'RnnModel.pt'))\n",
    "validate_test(model=RNN, epoch=0, use_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
